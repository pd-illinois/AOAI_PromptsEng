{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Examples for Langchains and Azure OpenAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os module & the OpenAI Python library for calling the OpenAI API \n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "from os import path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "* https://python.langchain.com/en/latest/modules/models/llms/integrations/azure_openai_example.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using LLM Models**\n",
    "1) Completion API with Text in Text Out Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (0.0.178)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from langchain) (1.4.32)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from langchain) (1.21.5)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from langchain) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (5.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2021.10.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pdhiman\\anaconda3\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4\n"
     ]
    }
   ],
   "source": [
    "# Configure OpenAI API\n",
    "# Load config values\n",
    "# Setting up the deployment name\n",
    "gpt_model_name = \"gpt-4\"\n",
    "print(gpt_model_name)\n",
    "\n",
    "# This is set to `azure`\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "#API_KEY = openai.api_key\n",
    "assert API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai.api_base = \"<your URL>\"\n",
    "\n",
    "# The Azure OPENAI API version.\n",
    "openai.api_version = \"2023-03-15-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Azure OpenAI\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=\"text-davinci-003\" ,\n",
    "    openai_api_key= API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Q: What did the baby corn say to the mama corn?\n",
      "A: Where's Popcorn?\n"
     ]
    }
   ],
   "source": [
    "joke = llm(\"Tell me a dad joke\")\n",
    "print(joke)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ChatAPI** for using Chat GPT Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! deployment_id is not default parameter.\n",
      "                    deployment_id was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_id is what you intended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Electric vehicles are becoming increasingly popular in the US market. They are eco-friendly, offer efficiency, and are attractive to consumers seeking cost savings. Federal and state incentives for EV purchases have helped drive adoption rates. However, concerns over range anxiety and the availability of charging infrastructure remain challenges for widespread adoption. Overall, the future looks bright for electric vehicles in the US.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(model='gpt-35-turbo',\n",
    "                  deployment_id = \"gpt-35-turbo\",\n",
    "                  temperature=0.9,\n",
    "                  openai_api_key=API_KEY)\n",
    "\n",
    "response = chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You are an AI assistant that helps a user with marketing content. Keep responses short and under 5 sentences.\"),\n",
    "        HumanMessage(content=\"Write a review of Electric vehicles in US\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embeddings**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1536\n",
      "[0.009326309897005558, -0.0006310197059065104, 0.006163125857710838, -0.015400114469230175, -0.013527460396289825]\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "openai_embed = OpenAIEmbeddings(model='text-embedding-ada-002',\n",
    "                                openai_api_key=API_KEY)\n",
    "\n",
    "query_embeddings = openai_embed.embed_query(\"The sky is blue\") \n",
    "\n",
    "print(type(query_embeddings))\n",
    "print(len(query_embeddings))\n",
    "print(query_embeddings[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Prompt Templates** for use input and capturing any variables / non static informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL PROMPT: Write a small advertisement a new Headphones and its description Best headphones?\n",
      " We've got them! \n",
      "\n",
      "Introducing the latest in sound technology, our new headphones make listening to music a truly immersive experience. With crystal-clear audio, deep bass, and noise-cancelling capabilities, these headphones will take your music experience to the next level. They come with a long-lasting battery life and a comfortable, lightweight design, so you can enjoy your tunes all day without having to worry about a recharge. Plus, they look great too, with a sleek, modern design that will look good no matter where you take them. Get ready to experience music like never before, with our amazing new headphones!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define a prompt template with placeholders for input variables.\n",
    "prompt_template = PromptTemplate(\n",
    "        template = 'Write a small advertisement a new {product} and its description {product_desc}?',\n",
    "        input_variables = ['product', 'product_desc']\n",
    ")\n",
    "\n",
    "# Create the final prompt by filling in the defined variables.\n",
    "final_prompt = prompt_template.format(product='Headphones',  product_desc='Best headphones')\n",
    "print(\"FINAL PROMPT: \" + final_prompt)\n",
    "\n",
    "response = llm(final_prompt) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Experience the thrill of a new electric vehicle in Iceland! Our electric vehicle is perfect for exploring the breathtaking scenery of Iceland. With its powerful motor, you will be able to navigate the rugged terrain of the landscape with ease. Enjoy a smooth, quiet ride as you take in the natural beauty of Iceland. Our electric vehicle offers superior performance with a range of up to 300 kilometers. It has a modern design, stylish looks, and is loaded with features. Don't miss out on this amazing opportunity to explore Iceland in the comfort and style of a new electric vehicle.\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt_template.format(product ='Electric Vehicle', product_desc='Iceland')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Structured Output Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the schema\n",
    "\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"product\", description=\"This is a product\"),\n",
    "    ResponseSchema(name=\"product_desc\", description=\"This is a short description of the product\")\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"product\": string  // This is a product\n",
      "\t\"product_desc\": string  // This is a short description of the product\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# 2. Generates output format instructions which can be included in your prompt.\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print (format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL PROMPT:\n",
      "\n",
      "You will be given a product by the user.\n",
      "Please provide a imaginary, creative and non offensive product name and a short description of the product.\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"product\": string  // This is a product\n",
      "\t\"product_desc\": string  // This is a short description of the product\n",
      "}\n",
      "```\n",
      "\n",
      "% PRODUCT:\n",
      "Iphone\n",
      "\n",
      "YOUR RESPONSE:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Incorporate into final prompt.\n",
    "\n",
    "template = '''\n",
    "You will be given a product by the user.\n",
    "Please provide a imaginary, creative and non offensive product name and a short description of the product.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "% PRODUCT:\n",
    "{product}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(product=\"Iphone\")\n",
    "print('FINAL PROMPT:')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"product\": \"Iphone\", \n",
      "\t\"product_desc\": \"A sleek and stylish smartphone that offers cutting edge features and the latest technology.\" \n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# 4. LLM now outputs an easily parsable response.\n",
    "\n",
    "response = llm(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A sleek and stylish smartphone that offers cutting edge features and the latest technology.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Output parser can extract named fields in the schema.\n",
    "\n",
    "output_parser.parse(response)['product_desc']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential Chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain component 1: \n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "template1 = \"\"\"You will be given an error from the user. Please provide a possible solution.\n",
    "\n",
    "% ERROR\n",
    "{error}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template1 = PromptTemplate(input_variables=[\"error\"], template=template1)\n",
    "\n",
    "# LLMChain is a simple chain which takes a prompt template, formats with user input and returns LLM output.\n",
    "error_chain = LLMChain(llm=llm, prompt=prompt_template1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain component 2: \n",
    "\n",
    "template2 = \"\"\"Given the error message, provide a short solution for fixing it.\n",
    "\n",
    "% MESSAGE\n",
    "{message}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template2 = PromptTemplate(input_variables=[\"message\"], template=template2)\n",
    "\n",
    "message_chain = LLMChain(llm=llm, prompt=prompt_template2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Creates a completion for the provided prompt, parameters and chosen model. Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mThis error is caused when a number is divided by zero. To solve this error, make sure that the number being divided is not zero.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Creates a completion for the provided prompt, parameters and chosen model. Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 56 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Creates a completion for the provided prompt, parameters and chosen model. Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 52 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Requests to the Creates a completion for the provided prompt, parameters and chosen model. Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 48 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: Requests to the Creates a completion for the provided prompt, parameters and chosen model. Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 40 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Requests to the Creates a completion for the provided prompt, parameters and chosen model. Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pdhiman\\pdDev\\PromptEngineering\\LangchainExamples.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pdhiman/pdDev/PromptEngineering/LangchainExamples.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m overall_chain \u001b[39m=\u001b[39m SimpleSequentialChain(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pdhiman/pdDev/PromptEngineering/LangchainExamples.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     chains\u001b[39m=\u001b[39m[error_chain, message_chain],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pdhiman/pdDev/PromptEngineering/LangchainExamples.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pdhiman/pdDev/PromptEngineering/LangchainExamples.ipynb#X40sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m chain_output \u001b[39m=\u001b[39m overall_chain\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mZeroDivisionError\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:236\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    130\u001b[0m     inputs,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\chains\\sequential.py:177\u001b[0m, in \u001b[0;36mSimpleSequentialChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    175\u001b[0m color_mapping \u001b[39m=\u001b[39m get_color_mapping([\u001b[39mstr\u001b[39m(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchains))])\n\u001b[0;32m    176\u001b[0m \u001b[39mfor\u001b[39;00m i, chain \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchains):\n\u001b[1;32m--> 177\u001b[0m     _input \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39;49mrun(_input, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child())\n\u001b[0;32m    178\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrip_outputs:\n\u001b[0;32m    179\u001b[0m         _input \u001b[39m=\u001b[39m _input\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:236\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    130\u001b[0m     inputs,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\chains\\llm.py:69\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[0;32m     65\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     66\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m     67\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     68\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m---> 69\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\chains\\llm.py:79\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m     78\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m---> 79\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[0;32m     80\u001b[0m     prompts, stop, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m     81\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\llms\\base.py:134\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    128\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    129\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m    130\u001b[0m     stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    131\u001b[0m     callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    132\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    133\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\llms\\base.py:191\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    190\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 191\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    192\u001b[0m run_manager\u001b[39m.\u001b[39mon_llm_end(output)\n\u001b[0;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\llms\\base.py:185\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[0;32m    180\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    181\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts, invocation_params\u001b[39m=\u001b[39mparams\n\u001b[0;32m    182\u001b[0m )\n\u001b[0;32m    183\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     output \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 185\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    186\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    187\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    189\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    190\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\llms\\openai.py:314\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[1;34m(self, prompts, stop, run_manager)\u001b[0m\n\u001b[0;32m    312\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    313\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\u001b[39mself\u001b[39m, prompt\u001b[39m=\u001b[39m_prompts, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m    315\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreaming:\n\u001b[0;32m    317\u001b[0m     \u001b[39m# Can't update token usage if streaming\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\llms\\openai.py:106\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[1;34m(llm, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\tenacity\\__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    323\u001b[0m     retry_exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m--> 325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\tenacity\\__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreraise\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mNoReturn:\n\u001b[0;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_attempt\u001b[39m.\u001b[39mfailed:\n\u001b[1;32m--> 158\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_attempt\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\langchain\\llms\\openai.py:104\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    211\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    222\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    619\u001b[0m         )\n\u001b[0;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    629\u001b[0m         ),\n\u001b[0;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pdhiman\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Requests to the Creates a completion for the provided prompt, parameters and chosen model. Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit."
     ]
    }
   ],
   "source": [
    "overall_chain = SimpleSequentialChain(\n",
    "    chains=[error_chain, message_chain],\n",
    "    verbose=True)\n",
    "chain_output = overall_chain.run(\"ZeroDivisionError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chain_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pdhiman\\pdDev\\PromptEngineering\\LangchainExamples.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pdhiman/pdDev/PromptEngineering/LangchainExamples.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(chain_output)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chain_output' is not defined"
     ]
    }
   ],
   "source": [
    "print(chain_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More Features like Q&A , document loader , text splitting and Agents**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of The Merchant of Venice, by William Shakespeare\n",
      "Document length in characters: 154211\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import GutenbergLoader\n",
    "\n",
    "# Load a long document.\n",
    "loader = GutenbergLoader('https://www.gutenberg.org/cache/epub/1515/pg1515.txt')\n",
    "doc = loader.load()\n",
    "\n",
    "print(doc[0].page_content[:80].rstrip())\n",
    "print('Document length in characters:', len(doc[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE PRINCE OF MOROCCO, suitor to Portia\\r\\n\\n\\nTHE PRINCE OF ARRAGON, suitor to Portia\\r\\n\\n\\nANTONIO, a merchant of Venice\\r\\n\\n\\nBASSANIO, his friend, suitor to Portia\\r\\n\\n\\nGRATIANO, friend to Antonio and Bassanio\\r\\n\\n\\nSOLANIO, friend to Antonio and Bassanio\\r\\n\\n\\nSALARINO, friend to Antonio and Bassanio\\r\\n\\n\\nLORENZO, in love with Jessica\\r\\n\\n\\nSHYLOCK, a rich Jew\\r\\n\\n\\nTUBAL, a Jew, his friend\\r\\n\\n\\nLAUNCELET GOBBO, a clown, servant to Shylock\\r\\n\\n\\nOLD GOBBO, father to Launcelet\\r\\n\\n\\nLEONARDO, servant to Bassanio\\r\\n\\n\\nBALTHAZAR, servant to Portia\\r\\n\\n\\nSTEPHANO, servant to Portia\\r\\n\\n\\nSALERIO, a messenger from Venice\\r\\n\\n\\n\\r\\n\\n\\nPORTIA, a rich heiress\\r\\n\\n\\nNERISSA, her waiting-woman\\r\\n\\n\\nJESSICA, daughter to Shylock\\r\\n\\n\\n\\r\\n\\n\\nMagnificoes of Venice, Officers of the Court of Justice, a Gaoler,\\r\\n\\n\\nServants and other Attendants\\r\\n\\n\\n\\r\\n\\n\\nSCENE: Partly at Venice, and partly at Belmont, the seat of Portia on\\r\\n\\n\\nthe Continent\\r\\n\\n\\n\\r\\n\\n\\n\\r\\n\\n\\nACT I\\r\\n\\n\\n\\r\\n\\n\\nSCENE I. Venice. A street.\\r\\n\\n\\n\\r\\n\\n\\n Enter Antonio, Salarino and Solanio.\\r\\n\\n\\n\\r\\n\\n\\nANTONIO.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# We need to split long documents into smaller chunks to stay under the LLM token limit.\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(doc[0].page_content)\n",
    "texts[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import BingSearchAPIWrapper, WikipediaAPIWrapper, PythonREPL\n",
    "\n",
    "# Bing API usage requires the BING_SUBSCRIPTION_KEY and BING_SEARCH_URL environment variables to be present.\n",
    "# bingapi = BingSearchAPIWrapper(k=1)\n",
    "# wikipedia = WikipediaAPIWrapper(top_k_results=1)\n",
    "# python_repl = PythonREPL()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
